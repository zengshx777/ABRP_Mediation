plot(fit, uniform=TRUE,
main="Classification Tree for Kyphosis")
text(fit, use.n=TRUE, all=TRUE, cex=.8)
plot(fit, uniform=TRUE,
main="Classification Tree for Kyphosis")
text(fit, use.n=TRUE, all=TRUE, cex=.8)
obs_fit=rpart(y~x+a1+a2+s1+s2,method="class")
plot(obs_fit, uniform=TRUE,
main="Classification For Randomization")
library(rpart)
obs_fit=rpart(y~x+a1+a2+s1+s2,method="class")
plot(obs_fit, uniform=TRUE,
main="Classification For Randomization")
text(fit, use.n=TRUE, all=TRUE, cex=.8)
library(rpart)
obs_fit=rpart(y~x+a1+a2+s1+s2,method="class")
plot(obs_fit, uniform=TRUE,
main="Classification For Observational Data")
text(fit, use.n=TRUE, all=TRUE, cex=.8)
rand_fit=rpart(y_rand~x_rand+a1_rand+a2_rand+s1_rand+s2_rand,method="class")
plot(rand_fit, uniform=TRUE,
main="Classification For Randomization Data")
text(rand_fit, use.n=TRUE, all=TRUE, cex=.8)
##
library(mvtnorm)
##Data Size
n_obv=1000
n_ran=1000
x=rmvnorm(n_obv,sigma=diag(c(1,1,1,1)))
a1=0.3*x[,1]+0.4*x[,2]-0.2*x[,3]+rnorm(n_obv,sd=0.5)
a2=0.4*x[,1]+0.6*x[,4]+rnorm(n_obv,sd=0.4)
s1=0.2*a1+0.3*x[,2]+0.3*x[,4]+rcauchy(n_obv)
s2=0.2*a1+0.2*a2+0.3*x[,3]+rgamma(n_obv,shape=2,rate=1)
probit=0.2*x[,1]+0.2*x[,2]+log(abs(a1))+0.3*a2+0.5*s1+rnorm(n_obv,sd=2)
y=probit>0
x_rand=rmvnorm(n_obv,sigma=diag(c(1,1,1,1)))
a1_rand=rnorm(n_obv,sd=0.5)
a2_rand=rnorm(n_obv,sd=0.4)
s1_rand=rcauchy(n_obv)
s2_rand=rgamma(n_obv,shape=2,rate=1)
probit_rand=0.2*x_rand[,1]+0.2*x_rand[,2]+log(abs(a1_rand))+0.3*a2_rand+0.5*s1_rand+rnorm(n_obv,sd=2)
y_rand=probit_rand>0
##Decision Tree
library(rpart)
obs_fit=rpart(y~x+a1+a2+s1+s2,method="class")
plot(obs_fit, uniform=TRUE,
main="Classification For Observational Data")
text(fit, use.n=TRUE, all=TRUE, cex=.8)
rand_fit=rpart(y_rand~x_rand+a1_rand+a2_rand+s1_rand+s2_rand,method="class")
plot(rand_fit, uniform=TRUE,
main="Classification For Randomization Data")
text(rand_fit, use.n=TRUE, all=TRUE, cex=.8)
probit_rand=0.2*x_rand[,1]+0.2*x_rand[,2]+0.3*a2_rand+0.5*s1_rand+rnorm(n_obv,sd=2)
##
library(mvtnorm)
##Data Size
n_obv=1000
n_ran=1000
x=rmvnorm(n_obv,sigma=diag(c(1,1,1,1)))
a1=0.3*x[,1]+0.4*x[,2]-0.2*x[,3]+rnorm(n_obv,sd=0.5)
a2=0.4*x[,1]+0.6*x[,4]+rnorm(n_obv,sd=0.4)
s1=0.2*a1+0.3*x[,2]+0.3*x[,4]+rcauchy(n_obv)
s2=0.2*a1+0.2*a2+0.3*x[,3]+rgamma(n_obv,shape=2,rate=1)
probit=0.2*x[,1]+0.2*x[,2]+0.3*a2+0.5*s1+rnorm(n_obv,sd=2)
y=probit>0
x_rand=rmvnorm(n_obv,sigma=diag(c(1,1,1,1)))
a1_rand=rnorm(n_obv,sd=0.5)
a2_rand=rnorm(n_obv,sd=0.4)
s1_rand=rcauchy(n_obv)
s2_rand=rgamma(n_obv,shape=2,rate=1)
probit_rand=0.2*x_rand[,1]+0.2*x_rand[,2]+0.3*a2_rand+0.5*s1_rand+rnorm(n_obv,sd=2)
y_rand=probit_rand>0
##Decision Tree
library(rpart)
obs_fit=rpart(y~x+a1+a2+s1+s2,method="class")
plot(obs_fit, uniform=TRUE,
main="Classification For Observational Data")
text(fit, use.n=TRUE, all=TRUE, cex=.8)
rand_fit=rpart(y_rand~x_rand+a1_rand+a2_rand+s1_rand+s2_rand,method="class")
plot(rand_fit, uniform=TRUE,
main="Classification For Randomization Data")
text(rand_fit, use.n=TRUE, all=TRUE, cex=.8)
##
library(mvtnorm)
##Data Size
n_obv=10000
n_ran=10000
x=rmvnorm(n_obv,sigma=diag(c(1,1,1,1)))
a1=0.3*x[,1]+0.4*x[,2]-0.2*x[,3]+rnorm(n_obv,sd=0.5)
a2=0.4*x[,1]+0.6*x[,4]+rnorm(n_obv,sd=0.4)
s1=0.2*a1+0.3*x[,2]+0.3*x[,4]+rcauchy(n_obv)
s2=0.2*a1+0.2*a2+0.3*x[,3]+rgamma(n_obv,shape=2,rate=1)
probit=0.2*x[,1]+0.2*x[,2]+0.3*a2+0.5*s1+rnorm(n_obv,sd=2)
y=probit>0
x_rand=rmvnorm(n_obv,sigma=diag(c(1,1,1,1)))
a1_rand=rnorm(n_obv,sd=0.5)
a2_rand=rnorm(n_obv,sd=0.4)
s1_rand=rcauchy(n_obv)
s2_rand=rgamma(n_obv,shape=2,rate=1)
probit_rand=0.2*x_rand[,1]+0.2*x_rand[,2]+0.3*a2_rand+0.5*s1_rand+rnorm(n_obv,sd=2)
y_rand=probit_rand>0
##Decision Tree
library(rpart)
obs_fit=rpart(y~x+a1+a2+s1+s2,method="class")
plot(obs_fit, uniform=TRUE,
main="Classification For Observational Data")
text(fit, use.n=TRUE, all=TRUE, cex=.8)
rand_fit=rpart(y_rand~x_rand+a1_rand+a2_rand+s1_rand+s2_rand,method="class")
plot(rand_fit, uniform=TRUE,
main="Classification For Randomization Data")
text(rand_fit, use.n=TRUE, all=TRUE, cex=.8)
##
library(mvtnorm)
##Data Size
n_obv=5000
n_ran=5000
x=rmvnorm(n_obv,sigma=diag(c(1,1,1,1)))
a1=0.3*x[,1]+0.4*x[,2]-0.2*x[,3]+rnorm(n_obv,sd=0.5)
a2=0.4*x[,1]+0.6*x[,4]+rnorm(n_obv,sd=0.4)
s1=0.2*a1+0.3*x[,2]+0.3*x[,4]+rcauchy(n_obv)
s2=0.2*a1+0.2*a2+0.3*x[,3]+rgamma(n_obv,shape=2,rate=1)
probit=0.2*x[,1]+0.2*x[,2]+0.3*a2+0.5*s1+rnorm(n_obv,sd=2)
y=probit>0
x_rand=rmvnorm(n_obv,sigma=diag(c(1,1,1,1)))
a1_rand=rnorm(n_obv,sd=0.5)
a2_rand=rnorm(n_obv,sd=0.4)
s1_rand=rcauchy(n_obv)
s2_rand=rgamma(n_obv,shape=2,rate=1)
probit_rand=0.2*x_rand[,1]+0.2*x_rand[,2]+0.3*a2_rand+0.5*s1_rand+rnorm(n_obv,sd=2)
y_rand=probit_rand>0
##Decision Tree
library(rpart)
obs_fit=rpart(y~x+a1+a2+s1+s2,method="class")
plot(obs_fit, uniform=TRUE,
main="Classification For Observational Data")
text(fit, use.n=TRUE, all=TRUE, cex=.8)
rand_fit=rpart(y_rand~x_rand+a1_rand+a2_rand+s1_rand+s2_rand,method="class")
plot(rand_fit, uniform=TRUE,
main="Classification For Randomization Data")
text(rand_fit, use.n=TRUE, all=TRUE, cex=.8)
obs_fit=randomForest(y~x+a1+a2+s1+s2)
##Random Forest
library(randomForest)
obs_fit=randomForest(y~x+a1+a2+s1+s2)
length(y)
dim(x)
s1
length(s1)
length(s2)
dim(x)
dim(y)
length(y)
obs_fit=randomForest(factor(y)~x+a1+a2+s1+s2)
obs_fit=randomForest(factor(y)~x+a1+a2+s1+s2,data=cbind(x,a1,a2,s1,s2,y))
obs_fit=rpart(y~x+a1+a2+s1+s2,method="class")
plot(obs_fit, uniform=TRUE,
main="Classification For Observational Data")
text(fit, use.n=TRUE, all=TRUE, cex=.8)
##
library(mvtnorm)
##Data Size
n_obv=1000
n_ran=1000
x=rmvnorm(n_obv,sigma=diag(c(1,1,1,1)))
a1=0.3*x[,1]+0.4*x[,2]-0.2*x[,3]+rnorm(n_obv,sd=0.5)
a2=0.4*x[,1]+0.6*x[,4]+rnorm(n_obv,sd=0.4)
s1=0.2*a1+0.3*x[,2]+0.3*x[,4]+rcauchy(n_obv)
s2=0.2*a1+0.2*a2+0.3*x[,3]+rgamma(n_obv,shape=2,rate=1)
probit=0.2*x[,1]+0.2*x[,2]+0.3*a2+0.5*s1+rnorm(n_obv,sd=2)
y=probit>0
x_rand=rmvnorm(n_obv,sigma=diag(c(1,1,1,1)))
a1_rand=rnorm(n_obv,sd=0.5)
a2_rand=rnorm(n_obv,sd=0.4)
s1_rand=rcauchy(n_obv)
s2_rand=rgamma(n_obv,shape=2,rate=1)
probit_rand=0.2*x_rand[,1]+0.2*x_rand[,2]+0.3*a2_rand+0.5*s1_rand+rnorm(n_obv,sd=2)
y_rand=probit_rand>0
##Decision Tree
library(rpart)
obs_fit=rpart(y~x+a1+a2+s1+s2,method="class")
plot(obs_fit, uniform=TRUE,
main="Classification For Observational Data")
text(fit, use.n=TRUE, all=TRUE, cex=.8)
rand_fit=rpart(y_rand~x_rand+a1_rand+a2_rand+s1_rand+s2_rand,method="class")
plot(rand_fit, uniform=TRUE,
main="Classification For Randomization Data")
text(rand_fit, use.n=TRUE, all=TRUE, cex=.8)
##Random Forest
library(randomForest)
obs_fit=randomForest(factor(y)~x+a1+a2+s1+s2)
obs_fit=randomForest(factor(y)~x+a1+a2+s1+s2)
obs_fit=randomForest(factor(y)~a1+a2+s1+s2)
obs_fit=randomForest(factor(y)~x[,1]+x[,2]+x[,3]+x[,4]+a1+a2+s1+s2)
importance(obs_fit)
rand_fit=randomForest(factor(y_rand)~x_rand[,1]+x_rand[,2]+x_rand[,3]+x_rand[,4]+a1_rand+a2_rand+s1_rand+s2_rand)
importance(rand_fit)
##
library(mvtnorm)
##Data Size
n_obv=10000
n_ran=10000
x=rmvnorm(n_obv,sigma=diag(c(1,1,1,1)))
a1=0.3*x[,1]+0.4*x[,2]-0.2*x[,3]+rnorm(n_obv,sd=0.5)
a2=0.4*x[,1]+0.6*x[,4]+rnorm(n_obv,sd=0.4)
s1=0.2*a1+0.3*x[,2]+0.3*x[,4]+rcauchy(n_obv)
s2=0.2*a1+0.2*a2+0.3*x[,3]+rgamma(n_obv,shape=2,rate=1)
probit=0.2*x[,1]+0.2*x[,2]+0.3*a2+0.5*s1+rnorm(n_obv,sd=2)
y=probit>0
x_rand=rmvnorm(n_obv,sigma=diag(c(1,1,1,1)))
a1_rand=rnorm(n_obv,sd=0.5)
a2_rand=rnorm(n_obv,sd=0.4)
s1_rand=rcauchy(n_obv)
s2_rand=rgamma(n_obv,shape=2,rate=1)
probit_rand=0.2*x_rand[,1]+0.2*x_rand[,2]+0.3*a2_rand+0.5*s1_rand+rnorm(n_obv,sd=2)
y_rand=probit_rand>0
##Decision Tree
library(rpart)
obs_fit=rpart(y~x+a1+a2+s1+s2,method="class")
plot(obs_fit, uniform=TRUE,
main="Classification For Observational Data")
text(fit, use.n=TRUE, all=TRUE, cex=.8)
rand_fit=rpart(y_rand~x_rand+a1_rand+a2_rand+s1_rand+s2_rand,method="class")
plot(rand_fit, uniform=TRUE,
main="Classification For Randomization Data")
text(rand_fit, use.n=TRUE, all=TRUE, cex=.8)
##Random Forest
library(randomForest)
obs_fit=randomForest(factor(y)~x[,1]+x[,2]+x[,3]+x[,4]+a1+a2+s1+s2)
importance(obs_fit)
rand_fit=randomForest(factor(y_rand)~x_rand[,1]+x_rand[,2]+x_rand[,3]+x_rand[,4]+a1_rand+a2_rand+s1_rand+s2_rand)
importance(rand_fit)
x_rand=rmvnorm(n_ran,sigma=diag(c(1,1,1,1)))
a1_rand=rnorm(n_ran,sd=0.5)
a2_rand=rnorm(n_ran,sd=0.4)
s1_rand=rcauchy(n_ran)
s2_rand=rgamma(n_ran,shape=2,rate=1)
probit_rand=0.2*x_rand[,1]+0.2*x_rand[,2]+0.3*a2_rand+0.5*s1_rand+rnorm(n_obv,sd=2)
y_rand=probit_rand>0
rand_fit=randomForest(factor(y_rand)~x_rand[,1]+x_rand[,2]+x_rand[,3]+x_rand[,4]+a1_rand+a2_rand+s1_rand+s2_rand)
importance(rand_fit)
obs_fit=randomForest(factor(y)~x[,1]+x[,2]+x[,3]+x[,4]+a1+a2+s1+s2)
importance(obs_fit)
obs_fit=rpart(y~x+a1+a2+s1+s2,method="class")
plot(obs_fit, uniform=TRUE,
main="Classification For Observational Data")
text(fit, use.n=TRUE, all=TRUE, cex=.8)
rand_fit=rpart(y_rand~x_rand+a1_rand+a2_rand+s1_rand+s2_rand,method="class")
plot(rand_fit, uniform=TRUE,
main="Classification For Randomization Data")
text(rand_fit, use.n=TRUE, all=TRUE, cex=.8)
post(rand_fit)
rpart.plot(rand_fit, box.palette="RdBu", shadow.col="gray", nn=TRUE)
plot(rand_fit, box.palette="RdBu", shadow.col="gray", nn=TRUE)
library(rpart.plot)
rpart.plot(rand_fit, box.palette="RdBu", shadow.col="gray", nn=TRUE)
rand_fit=randomForest(factor(y_rand)~x_rand[,1]+x_rand[,2]+x_rand[,3]+x_rand[,4]+a1_rand+a2_rand+s1_rand+s2_rand)
importance(rand_fit)
load("C:/Users/Shuxi ZENG/Dropbox/Third Year/FPCA_New/NewData/ELADSIGC data for Shuxi 2019-08-26.RData")
View(merged_adv_gcdata)
merged_adv_gcdata$hydroyear
unique(merged_adv_gcdata$hydroyear)
#Produce Figure 8
load("Figure5.RData")
load("Figure7.RData")
par(mfrow=c(3,1), mar = c(2,4,1.5,0))
#Result by method*subgroup*measure*(est,low,up)
ols=as.vector(t(T_MATRIX[c(1,6,11,16),]))
match=as.vector(t(T_MATRIX[c(1,6,11,16)+1,]))
ipw=as.vector(t(T_MATRIX[c(1,6,11,16)+2,]))
dr=as.vector(t(T_MATRIX[c(1,6,11,16)+3,]))
iv=as.vector(t(T_MATRIX[c(1,6,11,16)+4,]))
tau=as.vector(t(TAU[,c(4,5,6)]))
values<-c(ols,match,ipw,dr,iv,tau)
method=c(rep("OLS",36),rep("Matching",36),rep("IPW",36),
rep("Double Robust",36),rep("2SLS",36),rep("Bayesian",36))
#Grid for X
xgrid=seq(1,8,length=6)
grid=c(rep(xgrid[1],each=36),rep(xgrid[2],each=36),
rep(xgrid[3],each=36),rep(xgrid[4],each=36),
rep(xgrid[5],each=36),rep(xgrid[6],each=36))
#Shape of Points
type=c(rep(c(3,1,2),12),rep(c(4,1,2),12),rep(c(5,1,2),12),
rep(c(6,1,2),12),rep(c(7,1,2),12),rep(c(8,1,2),12))
#Group to Draw Liness
pair=as.vector(t(cbind(seq(1,143,length=72),seq(2,144,length=72),
seq(2,144,length=72))))
#Measures
measure=rep(rep(c("Confidence","Anxiety","Desperation"),each=3),24)
#Subgroup
ruralgroup=rep(rep(c("Rural Female","Rural Male",
"Urban Female","Urban Male"),each=9),6)
#Transform into Data frame
df<- data.frame(
Grid=grid,Values=values,type=as.factor(type),pairs=pair,
measure=factor(measure,levels=c("Confidence","Anxiety","Desperation")),
ruralgroup=factor(ruralgroup,levels=c("Rural Female","Rural Male",
"Urban Female","Urban Male"))
)
p7<-ggplot(df, aes(x=Grid, y=Values,group=pairs)) +
# Add points, whose color and shape varies with the "variable" column
geom_point(data=df,aes(shape=type),size=2, alpha=0.9) +
geom_line(aes(x=Grid,y=Values),linetype="dashed")+
scale_shape_manual(values=c(6,2,1,4,9,10,12,13),
labels=c("Lower Bound", "Upper Bound",
"Regression","Matching","IPW","Double Robust",
"2SLS","Bayesian"))+
# Provide breakpoints and respective labelings for the x-axis
#scale_x_continuous(breaks=xgrid, labels=c("OLS","MATCH","IPW","DR","2SLS","BAYES"))+
# Lay out plots in a grid fomat, with "measure" used as the vertical
# facet group and "ruralgender" used as the horizontal facet group
facet_grid(measure~ruralgroup) +
# Add horizontal lines at 0
geom_hline(aes(yintercept= 0), linetype="dotdash",alpha=0.5)+
# Add labels. Note that to rename the legend, you have to rename both the
# "shape" and the "color" variables.
labs(title = "", x = "", y="",
shape="") +
# Choose a grayscale palette
scale_color_grey() +
# Remove the default grey background
theme_bw() +
# Customizations. Center plot title, and remove background lines
theme(plot.title = element_text(hjust = 0.5),
panel.spacing.x = unit(0, "lines"),
axis.text.x=element_blank(),
axis.ticks.x=element_blank(),
legend.position="top",
panel.grid.major = element_blank(),
panel.grid.minor = element_blank())
#
#pdf("OtherMethod.pdf",height = 6,width=8.5)
p7
#dev.off()
setwd("C:/Users/Shuxi ZENG/Dropbox/Third Year/FPCA_New/FPCA_1005")
##Survival Curve Drawn
rm(list=ls())
# setwd("C:/Users/Shuxi ZENG/Dropbox/Third Year/FPCA_New/FPCA_1005")
load("ELADSIGC data for Shuxi 9.22.2019.RData")
f = 1
age.truncate.female = 18
source("Collapse_Data.R")
max_age=aggregate(gender.data$age_sample,by=list(gender.data$sname),max)$x
max_age
treat_ind=aggregate(gender.data$adv_cumulative,by=list(gender.data$sname),max)$x
treat_ind
survival.data=cbind(max_age,treat_ind,state=1)
head(survival.data)
survival.data=data.frame(age=max_age,group=treat_ind,state=1)
library(survival)
km_fit <- survfit(Surv(age, state) ~ 1, data=survival.data)
autoplot(km_fit)
plot(km_fit, xlab="Days", main = 'Kaplan Meyer Plot') #base graphics is always ready
plot(km_fit, xlab="Age in year",xlab=c(4,25),main = 'Kaplan Meyer Plot') #base graphics is always ready
plot(km_fit, xlab="Age in year",xlim=c(4,25),main = 'Kaplan Meyer Plot') #base graphics is always ready
library(ggplot2)
library(ggplot2)
autoplot(km_fit)
library(ggfortify)
install.packages(ggfortify)
install.packages("ggfortify")
library(ggfortify)
autoplot(km_fit)
autoplot(km_fit)+xlim(c(4,25))
autoplot(km_fit)+xlim(c(4,25))+xtitle("Kaplan Meyer Plot, Pooled Sample")+ylab("Survival Rate")
autoplot(km_fit)+xlim(c(4,25))+title("Kaplan Meyer Plot, Pooled Sample")+ylab("Survival Rate")
plot(km_fit, xlab="Age in year",xlim=c(4,25),main = 'Kaplan Meyer Plot, Pooled Sample') #base graphics is always ready
plot(km_fit, xlab="Age in year",xlim=c(3.9,25),main = 'Kaplan Meyer Plot, Pooled Sample') #base graphics is always ready
autoplot(km_fit)+xlim(c(3.9,25))+title("Kaplan Meyer Plot, Pooled Sample")+
ylab("Survival rate")+xlab("Age in year")
autoplot(km_fit)+xlim(c(3.9,25))+ggtitle("Kaplan Meyer Plot, Pooled Sample")+
ylab("Survival rate")+xlab("Age in year")
autoplot(km_fit)+xlim(c(3.9,25))+ggtitle("Kaplan Meyer Plot, Pooled Sample")+
ylab("Survival rate")+xlab("Age in year")+
theme(plot.title = element_text(hjust = 0.5))
table(treat_ind)
max_age=aggregate(gender.data$age_sample,by=list(gender.data$sname),max)$x
treat_ind=aggregate(gender.data$adv_cumulative,by=list(gender.data$sname),max)$x
coarse_summary=treat_ind
coarse_summary[treat_ind>=2]=2
coarse_summary=as.factor(coarse_summary)
survival.data=data.frame(age=max_age,group=coarse_summary,state=1)
km_fit <- survfit(Surv(age, state) ~ 1, data=survival.data)
#plot(km_fit, xlab="Age in year",xlim=c(3.9,25),main = 'Kaplan Meyer Plot, Pooled Sample') #base graphics is always ready
autoplot(km_fit)+xlim(c(3.9,25))+ggtitle("Kaplan Meyer Plot, Pooled Sample")+
ylab("Survival rate")+xlab("Age in year")+
theme(plot.title = element_text(hjust = 0.5))
km_fit_adv <- survfit(Surv(age, state) ~ coarse_summary, data=survival.data)
autoplot(km_fit_adv)
autoplot(km_fit_adv)+xlim(c(3.9,25))+ggtitle("Kaplan Meyer Plot, by Adversity")+
ylab("Survival rate")+xlab("Age in year")+
theme(plot.title = element_text(hjust = 0.5))
autoplot(km_fit_adv)+xlim(c(3.9,25))+ggtitle("Kaplan Meyer Plot, by Adversity")+
ylab("Survival rate")+xlab("Age in year")+
scale_color_brewer(labels=c("0", "1", "2+"))+
theme(plot.title = element_text(hjust = 0.5))
autoplot(km_fit_adv)+xlim(c(3.9,25))+ggtitle("Kaplan Meyer Plot, by Adversity")+
ylab("Survival rate")+xlab("Age in year")+
labs(color = "Legend Title\n")+
theme(plot.title = element_text(hjust = 0.5))
autoplot(km_fit_adv)+
labs(color = "Number of Adversities\n")+xlim(c(3.9,25))+ggtitle("Kaplan Meyer Plot, by Adversity")+
ylab("Survival rate")+xlab("Age in year")+
theme(plot.title = element_text(hjust = 0.5))
autoplot(km_fit_adv,legendLabs="Number of Adv")+xlim(c(3.9,25))+ggtitle("Kaplan Meyer Plot, by Adversity")+
ylab("Survival rate")+xlab("Age in year")+
theme(plot.title = element_text(hjust = 0.5))
autoplot(km_fit_adv,legendLabs="Number of Adv")+theme(legend.title = element_blank())+xlim(c(3.9,25))+ggtitle("Kaplan Meyer Plot, by Adversity")+
ylab("Survival rate")+xlab("Age in year")+
theme(plot.title = element_text(hjust = 0.5))
autoplot(km_fit_adv)+theme(legend.title = element_blank())+xlim(c(3.9,25))+ggtitle("Kaplan Meyer Plot, by Adversity")+
ylab("Survival rate")+xlab("Age in year")+labs(color="Number of Adversities")+
theme(plot.title = element_text(hjust = 0.5))
autoplot(km_fit_adv)+theme(legend.title = element_blank())+xlim(c(3.9,25))+ggtitle("Kaplan Meyer Plot, by Adversity")+
ylab("Survival rate")+xlab("Age in year")+
theme(plot.title = element_text(hjust = 0.5))
autoplot(km_fit_adv)+theme(legend.title = "number")+xlim(c(3.9,25))+ggtitle("Kaplan Meyer Plot, by Adversity")+
ylab("Survival rate")+xlab("Age in year")+
theme(plot.title = element_text(hjust = 0.5))
autoplot(km_fit_adv)+theme(legend.title = element_blank())+xlim(c(3.9,25))+ggtitle("Kaplan Meyer Plot, by Adversity")+
ylab("Survival rate")+xlab("Age in year")+ labs(fill = "Dose (mg)")+
theme(plot.title = element_text(hjust = 0.5))
autoplot(km_fit_adv)+xlim(c(3.9,25))+ggtitle("Kaplan Meyer Plot, by Adversity")+
ylab("Survival rate")+xlab("Age in year")+ labs(fill = "Dose (mg)")+
theme(plot.title = element_text(hjust = 0.5))
autoplot(km_fit_adv)+xlim(c(3.9,25))+ggtitle("Kaplan Meyer Plot, by Adversity")+
ylab("Survival rate")+xlab("Age in year")+ guide(fill = FALSE)+
labs(colour = "Gender") +
theme(plot.title = element_text(hjust = 0.5))
S
autoplot(km_fit_adv)+xlim(c(3.9,25))+ggtitle("Kaplan Meyer Plot, by Adversity")+
ylab("Survival rate")+xlab("Age in year")+ guides(fill = FALSE)+
labs(colour = "Gender") +
theme(plot.title = element_text(hjust = 0.5))
autoplot(km_fit_adv)+xlim(c(3.9,25))+ggtitle("Kaplan Meyer Plot, by Adversity")+
ylab("Survival rate")+xlab("Age in year")+ guides(fill = FALSE)+
labs(colour = "Number of Adv") +
scale_color_manual(labels = c("0", "1","2+"))+
theme(plot.title = element_text(hjust = 0.5))
autoplot(km_fit_adv)+xlim(c(3.9,25))+ggtitle("Kaplan Meyer Plot, by Adversity")+
ylab("Survival rate")+xlab("Age in year")+ guides(fill = FALSE)+
labs(colour = "Number of Adv") +
scale_color_manual(labels = c("0", "1","2+"),values=c(1,2,3))+
theme(plot.title = element_text(hjust = 0.5))
autoplot(km_fit_adv)+xlim(c(3.9,25))+ggtitle("Kaplan Meyer Plot, by Adversity")+
ylab("Survival rate")+xlab("Age in year")+ guides(fill = FALSE)+
labs(colour = "Number of Adv") +
scale_color_manual(labels = c("0", "1","2+"),values=c(0,1,2))+
theme(plot.title = element_text(hjust = 0.5))
autoplot(km_fit_adv)+xlim(c(3.9,25))+ggtitle("Kaplan Meyer Plot, by Adversity")+
ylab("Survival rate")+xlab("Age in year")+ guides(fill = FALSE)+
labs(colour = "Number of Adv") +
scale_color_manual(labels = c("0", "1","2+"),values=c(2,3,4))+
theme(plot.title = element_text(hjust = 0.5))
setwd("C:/Users/Shuxi ZENG/Dropbox/Things we generated during Shuxi's visit/R code/survival_plots")
library(survival)
library(ggplot2)
library(ggfortify)
##Survival Curve Drawn
rm(list=ls())
# setwd("C:/Users/Shuxi ZENG/Dropbox/Third Year/FPCA_New/FPCA_1005")
load("ELADSIGC data for Shuxi 9.22.2019.RData")
f = 1
age.truncate.female = 18
source("Collapse_Data.R")
max_age=aggregate(gender.data$age_sample,by=list(gender.data$sname),max)$x
treat_ind=aggregate(gender.data$adv_cumulative,by=list(gender.data$sname),max)$x
coarse_summary=treat_ind
coarse_summary[treat_ind>=2]=2
coarse_summary=as.factor(coarse_summary)
survival.data=data.frame(age=max_age,group=coarse_summary,state=1)
km_fit <- survfit(Surv(age, state) ~ 1, data=survival.data)
#plot(km_fit, xlab="Age in year",xlim=c(3.9,25),main = 'Kaplan Meyer Plot, Pooled Sample') #base graphics is always ready
autoplot(km_fit)+xlim(c(3.9,25))+ggtitle("Kaplan Meyer Plot, Pooled Sample")+
ylab("Survival rate")+xlab("Age in year")+
theme(plot.title = element_text(hjust = 0.5))
km_fit_adv <- survfit(Surv(age, state) ~ coarse_summary, data=survival.data)
autoplot(km_fit_adv)+xlim(c(3.9,25))+ggtitle("Kaplan Meyer Plot, by Adversity")+
ylab("Survival rate")+xlab("Age in year")+ guides(fill = FALSE)+
labs(colour = "Number of Adv") +
scale_color_manual(labels = c("0", "1","2+"),values=c(2,3,4))+
theme(plot.title = element_text(hjust = 0.5))
library(survival)
library(ggplot2)
library(ggfortify)
##Survival Curve Drawn
rm(list=ls())
# setwd("C:/Users/Shuxi ZENG/Dropbox/Third Year/FPCA_New/FPCA_1005")
load("ELADSIGC data for Shuxi 9.22.2019.RData")
f = 1
age.truncate.female = 18
source("Collapse_Data.R")
max_age=aggregate(gender.data$age_sample,by=list(gender.data$sname),max)$x
treat_ind=aggregate(gender.data$adv_cumulative,by=list(gender.data$sname),max)$x
coarse_summary=treat_ind
coarse_summary[treat_ind>=2]=2
coarse_summary=as.factor(coarse_summary)
survival.data=data.frame(age=max_age,group=coarse_summary,state=1)
km_fit <- survfit(Surv(age, state) ~ 1, data=survival.data)
#plot(km_fit, xlab="Age in year",xlim=c(3.9,25),main = 'Kaplan Meyer Plot, Pooled Sample') #base graphics is always ready
pdf("../../Figures/Survivalplots/KMplot_pool.pdf")
autoplot(km_fit)+xlim(c(3.9,25))+ggtitle("Kaplan Meyer Plot, Pooled Sample")+
ylab("Survival rate")+xlab("Age in year")+
theme(plot.title = element_text(hjust = 0.5))
dev.off()
km_fit_adv <- survfit(Surv(age, state) ~ coarse_summary, data=survival.data)
pdf("../../Figures/Survivalplots/KMplot_group.pdf")
autoplot(km_fit_adv)+xlim(c(3.9,25))+ggtitle("Kaplan Meyer Plot, by Adversity")+
ylab("Survival rate")+xlab("Age in year")+ guides(fill = FALSE)+
labs(colour = "Number of Adv") +
scale_color_manual(labels = c("0", "1","2+"),values=c(2,3,4))+
theme(plot.title = element_text(hjust = 0.5))
dev.off()
